# 20231124
## 0059
- cannot calculate loss based on preds object and monai tensor
```python
print(f'preds ({type(preds[0])}): ', len(preds))
print(f'label ({type(label)}): ', len(label))
print(len(preds[0]), len(label[0]), len(label[1]))
# print(f'preds ({type(preds[0])}): ', preds[0])
# print(f'label ({type(label[0])}): ', label[0])
bce_loss, dsc_loss = loss_fn(preds, label)
```
```bash
preds (<class 'monai.data.meta_tensor.MetaTensor'>):  1
label (<class 'monai.data.meta_tensor.MetaTensor'>):  2
2 3 3
net_output (<class 'list'>): 
target (<class 'monai.data.meta_tensor.MetaTensor'>): 
Traceback (most recent call last):
  File "train_brats2021.py", line 247, in <module>
    main()
  File "train_brats2021.py", line 211, in main
    train(args, epoch, model, train_loader, loss, optimizer, scheduler, scaler, writer, logger)
  File "train_brats2021.py", line 57, in train
    bce_loss, dsc_loss = loss_fn(preds, label)
  File "/home/tom/anaconda3/envs/brats2023/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tom/anaconda3/envs/brats2023/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tom/Documents/y4_t1/fyp/3DUNet-BraTS-PyTorch/utils/loss.py", line 132, in forward
    bce_loss = self.bce(net_output, target)
  File "/home/tom/anaconda3/envs/brats2023/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tom/anaconda3/envs/brats2023/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tom/anaconda3/envs/brats2023/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 725, in forward
    return F.binary_cross_entropy_with_logits(input, target,
  File "/home/tom/anaconda3/envs/brats2023/lib/python3.8/site-packages/torch/nn/functional.py", line 3176, in binary_cross_entropy_with_logits
    return handle_torch_function(
  File "/home/tom/anaconda3/envs/brats2023/lib/python3.8/site-packages/torch/overrides.py", line 1577, in handle_torch_function
    result = torch_func_method(public_api, types, args, kwargs)
  File "/home/tom/anaconda3/envs/brats2023/lib/python3.8/site-packages/monai/data/meta_tensor.py", line 245, in __torch_function__
    ret = super().__torch_function__(func, types, args, kwargs)
  File "/home/tom/anaconda3/envs/brats2023/lib/python3.8/site-packages/torch/_tensor.py", line 1386, in __torch_function__
    ret = func(*args, **kwargs)
  File "/home/tom/anaconda3/envs/brats2023/lib/python3.8/site-packages/torch/nn/functional.py", line 3192, in binary_cross_entropy_with_logits
    if not (target.size() == input.size()):
AttributeError: 'list' object has no attribute 'size'
```
- print shapes: 
```bash
preds (<class 'monai.data.meta_tensor.MetaTensor'>):  (2, 3, 128, 128, 128)
label (<class 'monai.data.meta_tensor.MetaTensor'>):  (3, 128, 128, 128)
label (<class 'monai.data.meta_tensor.MetaTensor'>):  (3, 128, 128, 128)
```

## 0117
- cannot get best epoch when testing
```bash
(brats2023) tom@b760:~/Documents/y4_t1/fyp/3DUNet-BraTS-PyTorch$ python train_brats2021.py --dataset brats2023 --data_root ../brats2023/ --cases_split ./data/split/brats2023_split_fold0.csv --epochs 3
20231124 01:19:40 INFO: -------------------- New Experiment --------------------
20231124 01:19:40 INFO: train_brats2021.py --dataset brats2023 --data_root ../brats2023/ --cases_split ./data/split/brats2023_split_fold0.csv --epochs 3
20231124 01:19:40 INFO: Namespace(amp=False, batch_size=2, beta1=0.9, beta2=0.999, block='plain', cases_split='./data/split/brats2023_split_fold0.csv', channels_list=[32, 64, 128, 256, 320, 320], clip_grad=False, comment='', data_parallel=False, data_root='../brats2023/', dataset='brats2023', deep_supervision=False, dropout_prob=0.0, ds_layer=4, epochs=3, eval_freq=10, exp_dir='exps_brats2023_unet_adamw_none_pos1.0_neg1.0_1124_011940', gpus=None, infer_batch_size=4, input_channels=4, kernel_size=3, lr=0.001, lr_gamma=0.1, milestones=[60, 80], neg_ratio=1.0, norm='instance', num_classes=3, num_workers=6, optim='adamw', patch_overlap=0.5, patch_size=128, pos_ratio=1.0, print_freq=5, save_freq=10, save_model=False, save_pred=False, scheduler='none', seed=1000, sliding_window_mode='constant', sw_batch_size=2, unet_arch='unet', warmup_epochs=5, weight_decay=0.0001, weight_path=None)
20231124 01:19:40 INFO: ==> Training starts...
20231124 01:20:05 INFO: Train: [0][1/2] Time 24.596 (24.596)    Data  4.307 ( 4.307)    BCE 0.7394 (0.7394)     Dice 0.9437 (0.9437) Loss 1.6830 (1.6830)
20231124 01:20:21 INFO: Train: [1][1/2] Time  5.391 ( 5.391)    Data  4.708 ( 4.708)    BCE 0.6884 (0.6884)     Dice 0.9341 (0.9341) Loss 1.6225 (1.6225)
20231124 01:20:26 INFO: Train: [2][1/2] Time  5.373 ( 5.373)    Data  4.695 ( 4.695)    BCE 0.6756 (0.6756)     Dice 0.9430 (0.9430) Loss 1.6187 (1.6187)
20231124 01:20:27 INFO: ==> Testing starts...
Traceback (most recent call last):
  File "train_brats2021.py", line 256, in <module>
    main()
  File "train_brats2021.py", line 240, in main
    best_epoch = val_leaderboard.get_best_epoch()
  File "/home/tom/Documents/y4_t1/fyp/3DUNet-BraTS-PyTorch/utils/misc.py", line 108, in get_best_epoch
    return self.case_rank.mean(1).idxmin()
  File "/home/tom/anaconda3/envs/brats2023/lib/python3.8/site-packages/pandas/core/series.py", line 2285, in idxmin
    i = self.argmin(axis, skipna, *args, **kwargs)
  File "/home/tom/anaconda3/envs/brats2023/lib/python3.8/site-packages/pandas/core/base.py", line 709, in argmin
    return nanops.nanargmin(  # type: ignore[return-value]
  File "/home/tom/anaconda3/envs/brats2023/lib/python3.8/site-packages/pandas/core/nanops.py", line 93, in _f
    return f(*args, **kwargs)
  File "/home/tom/anaconda3/envs/brats2023/lib/python3.8/site-packages/pandas/core/nanops.py", line 1116, in nanargmin
    result = values.argmin(axis)  # type: ignore[var-annotated]
ValueError: attempt to get argmin of an empty sequence
```

- solved: need to add `--val_freq` in order to update the leaderboard
## 1514
- example command and output of a single training:
```bash
python train_brats2021.py --dataset brats2023 --data_root ../brats2023/ --cases_split ./data/split/brats2023_split_fold0.csv --epochs 3 --eval_freq 1
```
- example console output
```bash
20231124 15:10:18 INFO: -------------------- New Experiment --------------------
20231124 15:10:18 INFO: train_brats2021.py --dataset brats2023 --data_root ../brats2023/ --cases_split ./data/split/brats2023_split_fold0.csv --epochs 3 --eval_freq 1
20231124 15:10:18 INFO: Namespace(amp=False, batch_size=2, beta1=0.9, beta2=0.999, block='plain', cases_split='./data/split/brats2023_split_fold0.csv', channels_list=[32, 64, 128, 256, 320, 320], clip_grad=False, comment='', data_parallel=False, data_root='../brats2023/', dataset='brats2023', deep_supervision=False, dropout_prob=0.0, ds_layer=4, epochs=3, eval_freq=1, exp_dir='exps_brats2023_unet_adamw_none_pos1.0_neg1.0_1124_151018', gpus=None, infer_batch_size=4, input_channels=4, kernel_size=3, lr=0.001, lr_gamma=0.1, milestones=[60, 80], neg_ratio=1.0, norm='instance', num_classes=3, num_workers=6, optim='adamw', patch_overlap=0.5, patch_size=128, pos_ratio=1.0, print_freq=5, save_freq=10, save_model=False, save_pred=False, scheduler='none', seed=1000, sliding_window_mode='constant', sw_batch_size=2, unet_arch='unet', warmup_epochs=5, weight_decay=0.0001, weight_path=None)
20231124 15:10:18 INFO: ==> Training starts...
20231124 15:10:43 INFO: Train: [0][1/2] Time 24.495 (24.495)    Data  4.205 ( 4.205)    BCE 0.7353 (0.7353)     Dice 0.9048 (0.9048) Loss 1.6401 (1.6401)
20231124 15:10:53 INFO: ==> Validation starts...
20231124 15:11:09 INFO: Val: [0][1/1]   Time 15.288 (15.288)    Dice_WT 0.488 (0.488)   Dice_TC 0.460 (0.460)   Dice_ET 0.181 (0.181)HD95_WT  87.248 ( 87.248)        HD95_TC 103.301 (103.301)       HD95_ET 121.478 (121.478)
20231124 15:11:09 INFO: ==> Validation ends...
20231124 15:11:14 INFO: Train: [1][1/2] Time  5.283 ( 5.283)    Data  4.593 ( 4.593)    BCE 0.6776 (0.6776)     Dice 0.8836 (0.8836) Loss 1.5612 (1.5612)
20231124 15:11:14 INFO: ==> Validation starts...
20231124 15:11:29 INFO: Val: [1][1/1]   Time 15.033 (15.033)    Dice_WT 0.437 (0.437)   Dice_TC 0.387 (0.387)   Dice_ET 0.259 (0.259)HD95_WT  84.687 ( 84.687)        HD95_TC  90.076 ( 90.076)       HD95_ET 109.643 (109.643)
20231124 15:11:29 INFO: ==> Validation ends...
20231124 15:11:34 INFO: Train: [2][1/2] Time  4.756 ( 4.756)    Data  4.050 ( 4.050)    BCE 0.6428 (0.6428)     Dice 0.8567 (0.8567) Loss 1.4995 (1.4995)
20231124 15:11:35 INFO: ==> Validation starts...
20231124 15:11:49 INFO: Val: [2][1/1]   Time 14.732 (14.732)    Dice_WT 0.529 (0.529)   Dice_TC 0.473 (0.473)   Dice_ET 0.410 (0.410)HD95_WT  78.027 ( 78.027)        HD95_TC  82.713 ( 82.713)       HD95_ET  94.038 ( 94.038)
20231124 15:11:49 INFO: ==> Validation ends...
20231124 15:11:49 INFO: ==> Testing starts...
type of case_rank:  <class 'pandas.core.frame.DataFrame'>
length of case_rank:  3
first 5 elements of case_rank:     Dice_WT  Dice_TC  Dice_ET  HD95_WT  HD95_TC  HD95_ET
0      2.0      2.0      3.0      3.0      3.0      3.0
1      3.0      3.0      2.0      2.0      2.0      2.0
2      1.0      1.0      1.0      1.0      1.0      1.0
20231124 15:11:49 INFO: ==> Testing ends...
```
## 1527
- no testing info
```bash
(brats2023) tom@b760:~/Documents/y4_t1/fyp/3DUNet-BraTS-PyTorch$ python train_brats2021.py --dataset brats2023 --data_root ../brats2023/ --cases_split ./data/split/brats2023_split_fold0.csv --epochs 5 --eval_freq 1
20231124 15:24:45 INFO: -------------------- New Experiment --------------------
20231124 15:24:45 INFO: train_brats2021.py --dataset brats2023 --data_root ../brats2023/ --cases_split ./data/split/brats2023_split_fold0.csv --epochs 5 --eval_freq 1
20231124 15:24:45 INFO: Namespace(amp=False, batch_size=2, beta1=0.9, beta2=0.999, block='plain', cases_split='./data/split/brats2023_split_fold0.csv', channels_list=[32, 64, 128, 256, 320, 320], clip_grad=False, comment='', data_parallel=False, data_root='../brats2023/', dataset='brats2023', deep_supervision=False, dropout_prob=0.0, ds_layer=4, epochs=5, eval_freq=1, exp_dir='exps_brats2023_unet_adamw_none_pos1.0_neg1.0_1124_152445', gpus=None, infer_batch_size=4, input_channels=4, kernel_size=3, lr=0.001, lr_gamma=0.1, milestones=[60, 80], neg_ratio=1.0, norm='instance', num_classes=3, num_workers=6, optim='adamw', patch_overlap=0.5, patch_size=128, pos_ratio=1.0, print_freq=5, save_freq=10, save_model=False, save_pred=False, scheduler='none', seed=1000, sliding_window_mode='constant', sw_batch_size=2, unet_arch='unet', warmup_epochs=5, weight_decay=0.0001, weight_path=None)
20231124 15:24:45 INFO: ==> Training starts...
20231124 15:25:10 INFO: Train: [0][1/2] Time 24.641 (24.641)    Data  4.050 ( 4.050)    BCE 0.7425 (0.7425)     Dice 0.9862 (0.9862) Loss 1.7286 (1.7286)
20231124 15:25:20 INFO: ==> Validation starts...
20231124 15:25:36 INFO: Val: [0][1/1]   Time 15.311 (15.311)    Dice_WT 0.016 (0.016)   Dice_TC 0.171 (0.171)   Dice_ET 0.281 (0.281)HD95_WT 105.896 (105.896)        HD95_TC 126.884 (126.884)       HD95_ET 126.851 (126.851)
20231124 15:25:36 INFO: ==> Validation ends...
20231124 15:25:41 INFO: Train: [1][1/2] Time  5.164 ( 5.164)    Data  4.485 ( 4.485)    BCE 0.6948 (0.6948)     Dice 0.9896 (0.9896) Loss 1.6844 (1.6844)
20231124 15:25:41 INFO: ==> Validation starts...
20231124 15:25:56 INFO: Val: [1][1/1]   Time 14.709 (14.709)    Dice_WT 0.001 (0.001)   Dice_TC 0.422 (0.422)   Dice_ET 0.291 (0.291)HD95_WT 131.960 (131.960)        HD95_TC 120.911 (120.911)       HD95_ET 125.809 (125.809)
20231124 15:25:56 INFO: ==> Validation ends...
20231124 15:26:01 INFO: Train: [2][1/2] Time  4.582 ( 4.582)    Data  3.884 ( 3.884)    BCE 0.6549 (0.6549)     Dice 0.9839 (0.9839) Loss 1.6389 (1.6389)
20231124 15:26:01 INFO: ==> Validation starts...
20231124 15:26:15 INFO: Val: [2][1/1]   Time 14.229 (14.229)    Dice_WT 0.041 (0.041)   Dice_TC 0.000 (0.000)   Dice_ET 0.038 (0.038)HD95_WT  71.616 ( 71.616)        HD95_TC 128.422 (128.422)       HD95_ET 129.680 (129.680)
20231124 15:26:15 INFO: ==> Validation ends...
20231124 15:26:20 INFO: Train: [3][1/2] Time  4.645 ( 4.645)    Data  3.951 ( 3.951)    BCE 0.6100 (0.6100)     Dice 0.9798 (0.9798) Loss 1.5897 (1.5897)
20231124 15:26:20 INFO: ==> Validation starts...
20231124 15:26:34 INFO: Val: [3][1/1]   Time 14.021 (14.021)    Dice_WT 0.002 (0.002)   Dice_TC 0.000 (0.000)   Dice_ET 0.000 (0.000)HD95_WT  90.999 ( 90.999)        HD95_TC  92.335 ( 92.335)       HD95_ET 129.385 (129.385)
20231124 15:26:34 INFO: ==> Validation ends...
20231124 15:26:39 INFO: Train: [4][1/2] Time  5.200 ( 5.200)    Data  4.496 ( 4.496)    BCE 0.5783 (0.5783)     Dice 0.9894 (0.9894) Loss 1.5678 (1.5678)
20231124 15:26:40 INFO: ==> Validation starts...
20231124 15:26:54 INFO: Val: [4][1/1]   Time 13.637 (13.637)    Dice_WT 0.000 (0.000)   Dice_TC 0.000 (0.000)   Dice_ET 0.000 (0.000)HD95_WT  98.290 ( 98.290)        HD95_TC 125.541 (125.541)       HD95_ET 130.689 (130.689)
20231124 15:26:54 INFO: ==> Validation ends...
20231124 15:26:54 INFO: ==> Testing starts...
20231124 15:26:54 INFO: ==> Testing ends...
```
- solved: need to assign test label to data split file (.csv) and modify utils/misc.py
